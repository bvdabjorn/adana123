{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Multi Target Random Forest Regression (MTRT)\n",
    "\n",
    "In this section we develop a multi target random forest regression for the prediction of a minimum and maximum price of laptop models.\n",
    "\n",
    "\n",
    "## 1. Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "## Edit Print options\n",
    "desired_width = 500\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dealing with missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Importing the preprocessed data\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"NAN\",\" \",\"nan\",\"NaN\"]\n",
    "data = pd.read_csv('datafile2.csv',na_values = missing_values)\n",
    "data2 = pd.read_csv('datafile2_test.csv',na_values = missing_values)\n",
    "\n",
    "## Removing missing values\n",
    "# data.dropna()\n",
    "\n",
    "## Just a temporary dataset to test the capabilities of the model\n",
    "temp_data = data[['brand','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                  'touchscreen','discrete_gpu','gpu','ram','ssd','detachable_keyboard','weight',\n",
    "                  'cpu_benchmark','gpu_benchmark','cpu_GHZ', 'min_price','max_price']]\n",
    "\n",
    "test_data = data2[['brand','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                   'touchscreen','discrete_gpu','gpu','ram','ssd', 'detachable_keyboard','weight',\n",
    "                   'cpu_benchmark','gpu_benchmark','cpu_GHZ']]\n",
    "\n",
    "concat_df = pd.concat([temp_data , test_data])\n",
    "\n",
    "##### TRAINING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "temp_data['detachable_keyboard'] = temp_data['detachable_keyboard'].fillna(0)\n",
    "# temp_data['detachable_keyboard'] = temp_data['detachable_keyboard'].astype(bool)\n",
    "temp_data['gpu_brand'] = temp_data['gpu_brand'].fillna(\"Unknown\", inplace = True) \n",
    "temp_data['cpu_type_name'] = temp_data.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "temp_data['gpu_type'] = temp_data['gpu_type'].fillna(\"No GPU\", inplace = True) \n",
    "temp_data['screen_surface'] = temp_data['screen_surface'].fillna(\"Unknown\", inplace = True) \n",
    "\n",
    "# ## Filling in missing values: NUMERICAL VARIABLES\n",
    "temp_data['weight'] = temp_data['weight'].fillna(temp_data['weight'].mean())\n",
    "temp_data['cpu_benchmark'] = temp_data['cpu_benchmark'].fillna(temp_data['cpu_benchmark'].mean())\n",
    "temp_data['gpu_benchmark'] = temp_data['gpu_benchmark'].fillna(temp_data['gpu_benchmark'].mean())\n",
    "temp_data['cpu_GHZ'] = temp_data['cpu_GHZ'].fillna(temp_data['cpu_GHZ'].mean())\n",
    "temp_data['pixels_x'] = temp_data['pixels_x'].fillna(1920)\n",
    "\n",
    "## Showing the data\n",
    "# data.head()\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "##### TRAINING & TESTING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "concat_df['detachable_keyboard'] = concat_df['detachable_keyboard'].fillna(0)\n",
    "# concat_df['detachable_keyboard'] = concat_df['detachable_keyboard'].astype(bool)\n",
    "concat_df['gpu_brand'] = concat_df['gpu_brand'].fillna(\"Unknown\", inplace = True) \n",
    "concat_df['cpu_type_name'] = concat_df.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "concat_df['gpu_type'] = concat_df['gpu_type'].fillna(\"No GPU\", inplace = True) \n",
    "concat_df['screen_surface'] = concat_df['screen_surface'].fillna(\"Unknown\", inplace = True) \n",
    "\n",
    "## Filling in missing values: NUMERICAL VARIABLES\n",
    "concat_df['weight'] = concat_df['weight'].fillna(concat_df['weight'].mean())\n",
    "concat_df['cpu_benchmark'] = concat_df['cpu_benchmark'].fillna(concat_df['cpu_benchmark'].mean())\n",
    "concat_df['gpu_benchmark'] = concat_df['gpu_benchmark'].fillna(concat_df['gpu_benchmark'].mean())\n",
    "concat_df['cpu_GHZ'] = concat_df['cpu_GHZ'].fillna(concat_df['cpu_GHZ'].mean())\n",
    "concat_df['pixels_x'] = concat_df['pixels_x'].fillna(1920)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance (Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting Data & Fitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=300, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Training Data ####\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat = temp_data[['brand','gpu','gpu_brand','cpu_type_name','gpu_type','screen_surface']]\n",
    "X_bin = temp_data[['touchscreen','discrete_gpu','detachable_keyboard']]\n",
    "X_num = temp_data[['screen_size','ram','ssd','weight','cpu_benchmark','cpu_GHZ','pixels_x']]\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies = pd.get_dummies(X_cat, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X = pd.concat([X_cat_dummies,X_bin,X_num], axis=1)\n",
    "# X = pd.concat([X_cat_dummies,X_num], axis=1)\n",
    "# X = X_cat_dummies\n",
    "\n",
    "## Defining output data\n",
    "Ya = temp_data[['min_price','max_price']]\n",
    "# Yb = temp_data[['min_price','diff_price']]\n",
    "\n",
    "########################################################################################\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat_test = concat_df[['brand','gpu','gpu_brand','cpu_type_name','gpu_type','screen_surface']]\n",
    "X_bin_test = concat_df[['touchscreen','discrete_gpu','detachable_keyboard']]\n",
    "X_num_test = concat_df[['screen_size','ram','ssd','weight','cpu_benchmark','cpu_GHZ','pixels_x']]\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies_test = pd.get_dummies(X_cat_test, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X_full = pd.concat([X_cat_dummies_test,X_bin_test,X_num_test], axis=1)\n",
    "X_train = X_full.head(len(data))\n",
    "X_test = X_full.tail(len(data2))\n",
    "\n",
    "########################################################################################\n",
    "## Splitting the dataset into train and test sets\n",
    "# Predict Minimum and Maximum prices\n",
    "X_train_a, X_test_a, Y_train_a, Y_test_a = train_test_split(X, Ya, test_size=0.33, random_state=42)\n",
    "# Predict Minimum price and deviation from this price\n",
    "# X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(X, Yb, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_a.head()\n",
    "\n",
    "## 2 models\n",
    "Model1 = RandomForestRegressor(n_estimators = 300,criterion='mae',random_state = 1)\n",
    "Model1.fit(X_train_a,Y_train_a)\n",
    "\n",
    "# Model2 = RandomForestRegressor(n_estimators = 200,criterion='mae',random_state = 0)\n",
    "# Model2.fit(X_train_b,Y_train_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Measuring Mean Summed Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: MSAE for predicting minimum and maximum  price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324.63657633136086\n",
      "326.5689369047622\n"
     ]
    }
   ],
   "source": [
    "## Predicting the target values\n",
    "Y_pred = Model1.predict(X_test_a)\n",
    "\n",
    "## Calculating the score\n",
    "MAE = mean_absolute_error(Y_test_a, Y_pred, multioutput='raw_values')\n",
    "print(MAE[0]+MAE[1])\n",
    "\n",
    "## Turn DF to array\n",
    "Y_test_array = Y_test_a.to_numpy()\n",
    "\n",
    "Sum_error = 0\n",
    "Y_pred_min_array = []\n",
    "for i in range(len(Y_pred)):\n",
    "#     print(Y_pred[i],Y_test_array[i])\n",
    "    Y_pred_min = Y_pred[i][0]\n",
    "    Y_pred_max = Y_pred[i][1]\n",
    "    Y_test_min = Y_test_array[i][0]\n",
    "    Y_test_max = Y_test_array[i][1]\n",
    "    \n",
    "    Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "    Error_min = abs(Y_pred_min - Y_test_min)\n",
    "    Error_max = abs(Y_pred_max - Y_test_max)\n",
    "    Total_error = Error_min + Error_max\n",
    "    \n",
    "    Sum_error = Sum_error + Total_error\n",
    "    counter = i\n",
    "\n",
    "Avg_error = Sum_error / counter\n",
    "MSAE = Avg_error\n",
    "print(MSAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: MSAE for predicting minimum price and price difference\n",
    "\n",
    "**Result:** No significant improvement was obtained. This is as expected because the regression tree considers the two outputs, min and max price, at the same time. They are not considered independent and the splits are based on improving both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = Model2.predict(X_test_b)\n",
    "\n",
    "# ## Turn DF to array\n",
    "# Y_test_array = Y_test_b.to_numpy()\n",
    "\n",
    "# Sum_error = 0\n",
    "# Y_pred_min_array = []\n",
    "# for i in range(len(Y_pred)):\n",
    "# #     print(Y_pred[i],Y_test_array[i])\n",
    "#     Y_pred_min = Y_pred[i][0]\n",
    "#     Y_pred_max = Y_pred_min + Y_pred[i][1]\n",
    "#     Y_test_min = Y_test_array[i][0]\n",
    "#     Y_test_max = Y_test_min + Y_test_array[i][1]\n",
    "    \n",
    "#     Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "#     Error_min = abs(Y_pred_min - Y_test_min)\n",
    "#     Error_max = abs(Y_pred_max - Y_test_max)\n",
    "#     Total_error = Error_min + Error_max\n",
    "    \n",
    "#     Sum_error = Sum_error + Total_error\n",
    "#     counter = i\n",
    "\n",
    "# Avg_error = Sum_error / counter\n",
    "# MSAE = Avg_error\n",
    "# print('The MSAE = ', round(MSAE,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the decision tree\n",
    "# FEATURE_NAMES = X_train.columns[:]\n",
    "\n",
    "\n",
    "# dot_data = export_graphviz(Model1,\n",
    "#                                out_file=None,\n",
    "#                                feature_names=FEATURE_NAMES,\n",
    "#                                filled = True)\n",
    "# graph = Source(dot_data)\n",
    "\n",
    "# # dot_data = io.StringIO()\n",
    "# # export_graphviz(Model1, out_file=dot_data, rounded=True, filled=True)\n",
    "# # filename = \"tree.png\"\n",
    "# # pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png(filename)\n",
    "# # plt.figure(figsize=(300,100))\n",
    "# # img = mpimg.imread(filename)\n",
    "# # imgplot = plt.imshow(img)\n",
    "# # plt.show()\n",
    "\n",
    "# plt.figure(figsize=(120,50))\n",
    "# plot_tree(Model1, feature_names=FEATURE_NAMES,fontsize=11, rounded=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results \n",
    "  \n",
    "# arange for creating a range of values \n",
    "# from min value of x to max  \n",
    "# value of x with a difference of 0.01  \n",
    "# between two consecutive values \n",
    "# X_grid = np.arange(X_test, max(x), 0.01)  \n",
    "# X_ram\n",
    "  \n",
    "# reshape for reshaping the data into a len(X_grid)*1 array,  \n",
    "# i.e. to make a column out of the X_grid value                   \n",
    "# X_grid = X_grid.reshape((len(X_grid), 1)) \n",
    "  \n",
    "# Scatter plot for original data \n",
    "# plt.scatter(x, y, color = 'blue')   \n",
    "  \n",
    "# plot predicted data \n",
    "# plt.plot(Y_pred_min_array,  \n",
    "#          color = 'green')  \n",
    "# plt.title('Random Forest Regression') \n",
    "# plt.xlabel('Position level') \n",
    "# plt.ylabel('Max_price') \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0            1            2\n",
      "0    28807  1127.365700  1193.300833\n",
      "1    22559   385.427733   401.750700\n",
      "2    28647   827.645917   859.047067\n",
      "3    22141   522.619500   542.157983\n",
      "4    26116  2150.110633  2332.082700\n",
      "5    27111  1362.687733  1404.905500\n",
      "6    23420   628.582983   649.678300\n",
      "7    21464   182.872150   189.135267\n",
      "8    29405   729.264450   761.076017\n",
      "9    27107   406.104800   414.568367\n",
      "10   26141   997.807500  1032.610933\n",
      "11   25928  1565.318000  1663.880400\n",
      "12   24845   710.034967   766.738733\n",
      "13   28804   339.491200   355.222050\n",
      "14   26772   611.625300   618.990300\n",
      "15   27413   886.264133   911.062567\n",
      "16    7261   819.436950   866.083367\n",
      "17   31424   761.371833   780.192500\n",
      "18    3940   404.038400   407.649100\n",
      "19   16238   533.887333   552.749467\n",
      "20   29407  1247.391467  1299.622050\n",
      "21   24011   351.231833   371.008367\n",
      "22    8542   370.185267   377.719533\n",
      "23   14448   726.980300   740.924367\n",
      "24   19611   229.921900   239.524233\n",
      "25   30068  1198.298333  1258.368500\n",
      "26   26802   272.059283   284.886050\n",
      "27   26129  1660.163167  1734.326267\n",
      "28    7080   583.330500   586.172183\n",
      "29   23193   527.550883   568.603633\n",
      "30   19853   227.916950   237.231517\n",
      "31   26592  2226.640267  2381.887933\n",
      "32   22554   176.654333   186.996217\n",
      "33   24213   609.202933   639.235933\n",
      "34   23608   204.542567   223.165733\n",
      "35    7874   304.974533   308.160700\n",
      "36   19312   149.386567   153.713067\n",
      "37   25260   845.375150   870.254350\n",
      "38   28220   699.232950   738.666017\n",
      "39   10550   443.992017   445.981733\n",
      "40   27583   246.608133   270.590867\n",
      "41    6341   622.599133   639.737400\n",
      "42   26128  1533.516433  1590.221167\n",
      "43   25062   777.035417   844.958567\n",
      "44   23817  1160.001183  1224.940983\n",
      "45   19840   760.129867   792.279867\n",
      "46   11094   386.661800   437.688150\n",
      "47   10683   196.640750   196.830083\n",
      "48   29850  1731.537133  1845.466367\n",
      "49   26117   421.274133   424.844083\n",
      "50   30071  1584.407733  1659.453833\n",
      "51   11530   431.319350   436.496133\n",
      "52   26123  1202.999050  1283.490950\n",
      "53   20497   683.046867   709.474083\n",
      "54   28641   322.053333   333.743233\n",
      "55   22370  1348.245550  1415.692033\n",
      "56   25269   376.782150   393.024933\n",
      "57   14891   336.496183   340.436750\n",
      "58   16237   920.406267   939.838200\n",
      "59   10366   169.076033   171.791467\n",
      "60   26591   298.731650   305.885650\n",
      "61   22372   235.895467   289.262717\n",
      "62   19151  1073.138133  1162.096300\n",
      "63    6719   555.630367   558.928833\n",
      "64   17470  1352.353983  1429.222483\n",
      "65   23603   130.149067   138.419300\n",
      "66   29629  1911.275167  1929.421967\n",
      "67   16239   507.514133   521.417800\n",
      "68   17744  1564.349567  1578.210533\n",
      "69    6998   876.750317   881.351967\n",
      "70   18991   196.640750   196.830083\n",
      "71   21215  1091.187133  1164.731700\n",
      "72   31415   629.633650   648.768233\n",
      "73   26132  1545.473367  1584.699567\n",
      "74   23191   559.726583   575.041267\n",
      "75   21208   176.261133   185.052483\n",
      "76   30752  1415.446900  1495.010467\n",
      "77   27883   575.345767   578.026417\n",
      "78   24020   364.938000   375.084383\n",
      "79   23195   631.628217   643.314617\n",
      "80   16244   215.951867   236.370200\n",
      "81   24218   741.875967   784.318283\n",
      "82   23421  1327.958117  1408.875267\n",
      "83   17274  1562.626600  1587.973100\n",
      "84   25064   171.806433   185.171867\n",
      "85    8219  1567.462517  1624.790183\n",
      "86   25264  1631.523700  1740.404600\n",
      "87   23604  1188.398567  1218.159450\n",
      "88    6639   673.309850   682.131133\n",
      "89   26105  1248.220983  1265.605833\n",
      "90   23116  1205.847717  1292.036033\n",
      "91   28040  1199.182000  1230.180933\n",
      "92   27884   608.324700   646.132267\n",
      "93   26363  1226.555850  1280.419950\n",
      "94   26803  1562.091100  1622.735500\n",
      "95   20283  1283.437817  1297.472933\n",
      "96   30517  1538.999200  1584.724033\n",
      "97    6753   204.444933   225.706300\n",
      "98   27736   498.619083   530.640700\n",
      "99   30062   231.016667   249.939983\n",
      "100  27241  2301.228600  2407.915800\n",
      "101  11532   420.477667   430.270167\n",
      "102  13770   359.784833   363.609000\n",
      "103  25261   814.807900   862.143800\n",
      "104  29204   267.437617   277.234650\n",
      "105  30992  1403.123267  1448.903300\n",
      "106  16230  1345.269717  1381.578217\n",
      "107  30759   866.555033   912.791033\n",
      "108  28644  1499.290667  1573.376267\n",
      "109  27579   430.377967   457.592783\n",
      "110  29205   357.252017   375.450350\n",
      "111  20088   643.310800   662.359600\n",
      "112  26122   461.429667   481.432200\n",
      "113  27416   306.345633   311.641717\n",
      "114   7266   793.077333   827.987200\n",
      "115   4002  1204.268033  1248.800517\n",
      "116   6782   378.864633   386.325667\n",
      "117  26776  1471.490050  1527.366117\n",
      "118  19852   240.262517   242.747267\n",
      "119  12293   236.380933   244.671050\n",
      "120  28800   308.281917   318.244050\n",
      "121  30518   591.596383   608.461650\n",
      "122  22861  1412.802617  1452.684450\n",
      "123  27411   685.220850   712.666633\n",
      "124  26595   119.726800   126.593433\n",
      "125  30997   541.092067   559.058117\n",
      "126   8227  1018.962083  1056.114967\n",
      "127  24435  1277.293100  1293.030600\n",
      "128  23811   811.401017   827.773217\n",
      "129  27738   395.846567   410.955833\n",
      "130  10827   380.246333   390.371067\n",
      "131  21206   616.099667   636.520167\n",
      "132  17757   649.592450   670.094417\n",
      "133  19303   667.372900   683.300300\n",
      "134  21460  1088.830267  1155.330267\n",
      "135  25934   748.312200   791.424583\n",
      "136  15327   256.158700   259.974633\n",
      "137  20735   574.329017   607.207150\n",
      "138  10548  1053.556550  1114.904133\n",
      "139  20103  1478.216417  1542.844267\n",
      "140  26364   849.648683   916.006800\n",
      "141  26771   640.535300   657.180833\n",
      "142  12288   236.380933   244.671050\n",
      "143   7267   894.770700   930.363633\n",
      "144  16692   844.128100   860.737617\n",
      "145   7859   832.387700   837.463433\n",
      "146  27739   683.610433   702.842467\n",
      "147  26100  1783.177800  1865.718400\n",
      "148  23221   627.629867   663.600650\n",
      "149  25442   275.310583   283.963183\n",
      "150  22146   757.999083   823.799600\n",
      "151  20746   877.877300   917.934333\n",
      "152  29627  1350.829833  1354.570000\n",
      "153  22562   859.429383   879.494767\n",
      "154  11535   247.394383   254.336683\n",
      "155  27881   614.447467   636.690067\n",
      "156  26774   526.563100   547.381450\n",
      "157  26962  1135.547267  1235.629100\n",
      "158  23818  1477.359800  1527.339833\n",
      "159   4045   484.428900   492.681800\n",
      "160  25931  1592.787367  1621.766233\n",
      "161  20104  1294.895883  1365.621650\n",
      "162  24212   618.927850   643.008017\n",
      "163   3900   364.124467   372.686767\n",
      "164  11946   625.208200   641.375250\n",
      "165  20498   415.940383   423.189467\n",
      "166  17743  1441.601467  1485.349733\n",
      "167  28801  1462.362500  1509.744017\n",
      "168  19608   143.700767   150.841267\n",
      "169  27108   616.216150   643.632350\n",
      "170  30294   681.785167   709.118100\n",
      "171  17276  1322.846467  1366.312567\n",
      "172  16241  1345.292433  1379.569933\n",
      "173  20287   823.481417   880.847250\n",
      "174  31194   390.958467   405.348583\n",
      "175  30287   538.940867   548.843067\n",
      "176   3991   663.244900   673.805367\n",
      "177  23816   432.059400   448.620267\n",
      "178  26099   820.683767   874.195567\n",
      "179  30295  1885.648600  1994.077600\n",
      "180  20511   582.463300   602.289700\n",
      "181  13245  1054.208600  1094.745800\n",
      "182  29841  1523.845250  1660.203683\n",
      "183  23611   935.913417   982.831217\n",
      "184  11941   652.646900   704.048633\n",
      "185  21207   734.418100   763.774033\n",
      "186  17474   842.685467   857.981250\n",
      "187  26805   511.244033   532.122317\n",
      "188  26104  1753.166283  1913.731750\n",
      "189   7504  1212.215967  1249.693917\n",
      "190  28222   204.542567   223.165733\n",
      "191  26362   240.743467   252.372617\n",
      "192  28980   390.147850   408.610383\n",
      "193  26587  1390.604700  1431.247733\n",
      "194  25933  1525.875733  1568.311417\n",
      "195  26134   819.643133   859.183400\n",
      "196   6648   457.273933   486.238667\n",
      "197  25055   308.915200   314.981683\n",
      "198  18665  1416.014583  1468.425567\n",
      "199  23618   204.058167   233.400233\n",
      "200  24629   563.111483   583.247350\n",
      "201  23201   530.951633   553.125600\n",
      "202  29849   365.147500   382.656467\n",
      "203  26961  1784.798883  1969.262200\n",
      "204  28482  1333.650833  1394.711100\n",
      "205  28979  1196.458567  1243.843300\n",
      "206  31191  1194.011600  1247.970933\n",
      "207   8960   912.458950   926.043767\n",
      "208  29408   357.148333   365.655450\n",
      "209  23425   694.210533   738.521633\n",
      "210  23418   382.737467   405.839167\n",
      "211  14057  1696.392850  1761.655533\n",
      "212  20274   501.899333   540.829683\n",
      "213  30288  1883.201867  1966.383133\n",
      "214  27580  1560.242800  1644.769533\n",
      "215   9286   183.047600   187.298500\n",
      "216  27414   371.376467   376.081867\n",
      "217   8398   707.896100   772.750967\n",
      "218  21211  1290.668500  1373.126767\n",
      "219  22553  2337.634200  2383.319533\n",
      "220  28808   679.076000   727.349800\n",
      "221  23423  1513.222683  1658.426350\n"
     ]
    }
   ],
   "source": [
    "Model_Final = RandomForestRegressor(n_estimators = 300,criterion='mae',random_state = 1)\n",
    "Model_Final.fit(X_train,Ya)\n",
    "Y_pred_test = Model_Final.predict(X_test)\n",
    "\n",
    "RESULTS = []\n",
    "for i in range(len(data2)):\n",
    "    temp_result = []\n",
    "    temp_result.append(data2['id'][i])\n",
    "    temp_result.append(Y_pred_test[i][0])\n",
    "    temp_result.append(Y_pred_test[i][1])\n",
    "    RESULTS.append(temp_result)\n",
    "\n",
    "RESULTS = pd.DataFrame(RESULTS)\n",
    "print(RESULTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS.to_csv(\"/Users/Simon/Documents/GitHub/adana123/RESULTS.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
