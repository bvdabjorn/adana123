{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Multi Target Random Forest Regression (MTRT)\n",
    "\n",
    "In this section we develop a multi target random forest regression for the prediction of a minimum and maximum price of laptop models.\n",
    "\n",
    "\n",
    "## 1. Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "## Edit Print options\n",
    "desired_width = 500\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dealing with missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Importing the preprocessed data\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"NAN\",\" \",\"nan\",\"NaN\",\"\"]\n",
    "data = pd.read_csv('datafile2.csv',na_values = missing_values)\n",
    "data2 = pd.read_csv('datafile2_test.csv',na_values = missing_values)\n",
    "\n",
    "## Removing missing values\n",
    "# data.dropna()\n",
    "\n",
    "## Just a temporary dataset to test the capabilities of the model\n",
    "temp_data = data[['brand','base_name','os_details','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                  'touchscreen','discrete_gpu','gpu','ram','ssd','detachable_keyboard','weight',\n",
    "                  'cpu_benchmark','gpu_benchmark','cpu_GHZ','cpu_core','threading','pc_name','min_price','max_price']]\n",
    "\n",
    "test_data = data2[['brand','base_name','os_details','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                   'touchscreen','discrete_gpu','gpu','ram','ssd', 'detachable_keyboard','weight',\n",
    "                   'cpu_benchmark','gpu_benchmark','cpu_GHZ','cpu_core','threading','pc_name']]\n",
    "\n",
    "concat_df = pd.concat([temp_data , test_data])\n",
    "concat_df.to_csv(\"/Users/Simon/Documents/GitHub/adana123/concat_df1.csv\",header=True,index=True)\n",
    "\n",
    "##### TRAINING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "detach_key = int(temp_data.loc[:,'detachable_keyboard'].mode())\n",
    "temp_data.loc[:,'detachable_keyboard'] = temp_data.loc[:,'detachable_keyboard'].fillna(0)\n",
    "\n",
    "temp_data.loc[:,'gpu_brand'] = temp_data.loc[:,'gpu_brand'].fillna(\"Unknown\", inplace = False) \n",
    "temp_data['cpu_type_name'] = temp_data.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "temp_data['gpu_type'] = temp_data['gpu_type'].fillna(\"No GPU\", inplace = False) \n",
    "temp_data.loc[:,'screen_surface'] = temp_data.loc[:,'screen_surface'].fillna(\"Unknown\", inplace = False) \n",
    "temp_data['os_details'] = temp_data['os_details'].fillna(\"Unknown\", inplace = False) \n",
    "temp_data['cpu_core'] = temp_data['cpu_core'].fillna(temp_data['cpu_core'].mode())\n",
    "\n",
    "# ## Filling in missing values: NUMERICAL VARIABLES\n",
    "temp_data['weight'] = temp_data['weight'].fillna(temp_data['weight'].mean())\n",
    "temp_data['cpu_benchmark'] = temp_data['cpu_benchmark'].fillna(temp_data['cpu_benchmark'].mean()) \n",
    "temp_data['gpu_benchmark'] = temp_data['gpu_benchmark'].fillna(temp_data['gpu_benchmark'].mean())\n",
    "temp_data['cpu_GHZ'] = temp_data['cpu_GHZ'].fillna(temp_data['cpu_GHZ'].mean())\n",
    "pixel_mode = int(temp_data.loc[:,'pixels_x'].mode())\n",
    "temp_data['pixels_x'] = temp_data['pixels_x'].fillna(pixel_mode) #Modus! Most frequent number! (median)\n",
    "\n",
    "## Showing the data\n",
    "# data.head()\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "##### TRAINING & TESTING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "detach_key = int(temp_data.loc[:,'detachable_keyboard'].mode())\n",
    "concat_df.loc[:,'detachable_keyboard'] = concat_df.loc[:,'detachable_keyboard'].fillna(detach_key)\n",
    "# print(concat_df['detachable_keyboard'])\n",
    "concat_df['gpu_brand'] = concat_df['gpu_brand'].fillna(\"Unknown\", inplace = False) \n",
    "concat_df['cpu_type_name'] = concat_df.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "\n",
    "concat_df['gpu_type'] = concat_df['gpu_type'].fillna(\"No GPU\", inplace = False)\n",
    "concat_df['gpu'] = concat_df['gpu'].fillna(\"No GPU\", inplace = False) \n",
    "concat_df['screen_surface'] = concat_df['screen_surface'].fillna(\"Unknown\", inplace = False) \n",
    "concat_df['os_details'] = concat_df['os_details'].fillna(\"Unknown\", inplace = False) \n",
    "concat_df['cpu_core'] = concat_df['cpu_core'].fillna(temp_data['cpu_core'].mode())\n",
    "\n",
    "## Filling in missing values: NUMERICAL VARIABLES\n",
    "concat_df['weight'] = concat_df['weight'].fillna(temp_data['weight'].mean())\n",
    "concat_df['cpu_benchmark'] = concat_df['cpu_benchmark'].fillna(temp_data['cpu_benchmark'].mean()) \n",
    "concat_df['gpu_benchmark'] = concat_df['gpu_benchmark'].fillna(temp_data['gpu_benchmark'].mean())\n",
    "concat_df['cpu_GHZ'] = concat_df['cpu_GHZ'].fillna(temp_data['cpu_GHZ'].mean())\n",
    "\n",
    "pixel_mode = int(temp_data.loc[:,'pixels_x'].mode())\n",
    "concat_df.loc[:,'pixels_x'] = concat_df.loc[:,'pixels_x'].fillna(pixel_mode)\n",
    "\n",
    "\n",
    "\n",
    "temp_data.to_csv(\"/Users/Simon/Documents/GitHub/adana123/temp_data.csv\",header=True,index=True)\n",
    "concat_df.to_csv(\"/Users/Simon/Documents/GitHub/adana123/concat_df2.csv\",header=True,index=True)\n",
    "\n",
    "\n",
    "#### Mean only from training set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance (Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting Data & Fitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=400, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Training Data ####\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat = temp_data[['cpu_core','brand','cpu_brand','gpu_brand','gpu','cpu_type_name','screen_surface']]#,'gpu_type','os_details','base_name'\n",
    "X_bin = temp_data[['touchscreen','discrete_gpu','detachable_keyboard','threading']]\n",
    "X_num = temp_data[['screen_size','ram','ssd','weight','cpu_GHZ','pixels_x','cpu_benchmark','gpu_benchmark']]\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies = pd.get_dummies(X_cat, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X = pd.concat([X_cat_dummies,X_bin,X_num], axis=1)\n",
    "# X = pd.concat([X_cat,X_bin,X_num], axis=1)\n",
    "# X = pd.concat([X_cat_dummies,X_num], axis=1)\n",
    "# X = X_cat_dummies\n",
    "\n",
    "## Defining output data\n",
    "Ya = temp_data[['min_price','max_price']]\n",
    "# Yb = temp_data[['min_price','diff_price']]\n",
    "\n",
    "########################################################################################\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat_test = concat_df[['cpu_core','brand','cpu_brand','gpu_brand','gpu','cpu_type_name','screen_surface']]#'pc_name','gpu_type','os_details','base_name'\n",
    "X_bin_test = concat_df[['touchscreen','discrete_gpu','detachable_keyboard','threading']]\n",
    "X_num_test = concat_df[['screen_size','ram','ssd','weight','cpu_GHZ','pixels_x','cpu_benchmark','gpu_benchmark']]\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies_test = pd.get_dummies(X_cat_test, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X_full = pd.concat([X_cat_dummies_test,X_bin_test,X_num_test], axis=1)\n",
    "X_train = X_full.head(len(data))\n",
    "X_test = X_full.tail(len(data2))\n",
    "\n",
    "########################################################################################\n",
    "## Splitting the dataset into train and test sets\n",
    "# Predict Minimum and Maximum prices\n",
    "X_train_a, X_test_a, Y_train_a, Y_test_a = train_test_split(X, Ya, test_size=0.33, random_state=42)\n",
    "# Predict Minimum price and deviation from this price\n",
    "# X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(X, Yb, test_size=0.33, random_state=42)\n",
    "\n",
    "# trainingdata = pd.concat([X_train_a, Y_train_a], axis=1, sort=False)\n",
    "# testingdata = pd.concat([X_test_a, Y_test_a], axis=1, sort=False)\n",
    "\n",
    "# trainingdata.to_csv(\"/Users/Simon/Documents/GitHub/adana123/trainingdata.csv\",header=True,index=True)\n",
    "# testingdata.to_csv(\"/Users/Simon/Documents/GitHub/adana123/testingdata.csv\",header=True,index=True)\n",
    "\n",
    "## 2 models\n",
    "Model1 = RandomForestRegressor(n_estimators = 400,criterion='mae',random_state = 1)\n",
    "Model1.fit(X_train_a,Y_train_a)\n",
    "\n",
    "# Model2 = RandomForestRegressor(n_estimators = 200,criterion='mae',random_state = 0)\n",
    "# Model2.fit(X_train_b,Y_train_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Measuring Mean Summed Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: MSAE for predicting minimum and maximum  price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.4823770710061\n",
      "315.3483436011905\n"
     ]
    }
   ],
   "source": [
    "## Predicting the target values\n",
    "Y_pred = Model1.predict(X_test_a)\n",
    "\n",
    "## Calculating the score\n",
    "MAE = mean_absolute_error(Y_test_a, Y_pred, multioutput='raw_values')\n",
    "print(MAE[0]+MAE[1])\n",
    "\n",
    "## Turn DF to array\n",
    "Y_test_array = Y_test_a.to_numpy()\n",
    "\n",
    "Sum_error = 0\n",
    "Y_pred_min_array = []\n",
    "for i in range(len(Y_pred)):\n",
    "#     print(Y_pred[i],Y_test_array[i])\n",
    "    Y_pred_min = Y_pred[i][0]\n",
    "    Y_pred_max = Y_pred[i][1]\n",
    "    Y_test_min = Y_test_array[i][0]\n",
    "    Y_test_max = Y_test_array[i][1]\n",
    "    \n",
    "    Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "    Error_min = abs(Y_pred_min - Y_test_min)\n",
    "    Error_max = abs(Y_pred_max - Y_test_max)\n",
    "    Total_error = Error_min + Error_max\n",
    "    \n",
    "    Sum_error = Sum_error + Total_error\n",
    "    counter = i\n",
    "\n",
    "Avg_error = Sum_error / counter\n",
    "MSAE = Avg_error\n",
    "print(MSAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: MSAE for predicting minimum price and price difference\n",
    "\n",
    "**Result:** No significant improvement was obtained. This is as expected because the regression tree considers the two outputs, min and max price, at the same time. They are not considered independent and the splits are based on improving both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = Model2.predict(X_test_b)\n",
    "\n",
    "# ## Turn DF to array\n",
    "# Y_test_array = Y_test_b.to_numpy()\n",
    "\n",
    "# Sum_error = 0\n",
    "# Y_pred_min_array = []\n",
    "# for i in range(len(Y_pred)):\n",
    "# #     print(Y_pred[i],Y_test_array[i])\n",
    "#     Y_pred_min = Y_pred[i][0]\n",
    "#     Y_pred_max = Y_pred_min + Y_pred[i][1]\n",
    "#     Y_test_min = Y_test_array[i][0]\n",
    "#     Y_test_max = Y_test_min + Y_test_array[i][1]\n",
    "    \n",
    "#     Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "#     Error_min = abs(Y_pred_min - Y_test_min)\n",
    "#     Error_max = abs(Y_pred_max - Y_test_max)\n",
    "#     Total_error = Error_min + Error_max\n",
    "    \n",
    "#     Sum_error = Sum_error + Total_error\n",
    "#     counter = i\n",
    "\n",
    "# Avg_error = Sum_error / counter\n",
    "# MSAE = Avg_error\n",
    "# print('The MSAE = ', round(MSAE,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the decision tree\n",
    "# FEATURE_NAMES = X_train.columns[:]\n",
    "\n",
    "\n",
    "# dot_data = export_graphviz(Model1,\n",
    "#                                out_file=None,\n",
    "#                                feature_names=FEATURE_NAMES,\n",
    "#                                filled = True)\n",
    "# graph = Source(dot_data)\n",
    "\n",
    "# # dot_data = io.StringIO()\n",
    "# # export_graphviz(Model1, out_file=dot_data, rounded=True, filled=True)\n",
    "# # filename = \"tree.png\"\n",
    "# # pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png(filename)\n",
    "# # plt.figure(figsize=(300,100))\n",
    "# # img = mpimg.imread(filename)\n",
    "# # imgplot = plt.imshow(img)\n",
    "# # plt.show()\n",
    "\n",
    "# plt.figure(figsize=(120,50))\n",
    "# plot_tree(Model1, feature_names=FEATURE_NAMES,fontsize=11, rounded=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results \n",
    "  \n",
    "# arange for creating a range of values \n",
    "# from min value of x to max  \n",
    "# value of x with a difference of 0.01  \n",
    "# between two consecutive values \n",
    "# X_grid = np.arange(X_test, max(x), 0.01)  \n",
    "# X_ram\n",
    "  \n",
    "# reshape for reshaping the data into a len(X_grid)*1 array,  \n",
    "# i.e. to make a column out of the X_grid value                   \n",
    "# X_grid = X_grid.reshape((len(X_grid), 1)) \n",
    "  \n",
    "# Scatter plot for original data \n",
    "# plt.scatter(x, y, color = 'blue')   \n",
    "  \n",
    "# plot predicted data \n",
    "# plt.plot(Y_pred_min_array,  \n",
    "#          color = 'green')  \n",
    "# plt.title('Random Forest Regression') \n",
    "# plt.xlabel('Position level') \n",
    "# plt.ylabel('Max_price') \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0            1            2\n",
      "0    28807  1126.516693  1194.133517\n",
      "1    22559   384.017723   401.133870\n",
      "2    28647   791.800283   821.233980\n",
      "3    22141   528.440970   546.200083\n",
      "4    26116  2124.674897  2300.583543\n",
      "5    27111  1412.425080  1463.226603\n",
      "6    23420   620.004083   646.379980\n",
      "7    21464   188.816333   195.450357\n",
      "8    29405   735.152740   771.372193\n",
      "9    27107   404.442920   413.626227\n",
      "10   26141   961.245523   995.154737\n",
      "11   25928  1654.770423  1747.151687\n",
      "12   24845   714.803043   771.859653\n",
      "13   28804   366.151860   378.754013\n",
      "14   26772   606.658737   614.803347\n",
      "15   27413   890.453257   923.237697\n",
      "16    7261   879.023217   923.084873\n",
      "17   31424   804.495977   825.724143\n",
      "18    3940   426.477407   436.223060\n",
      "19   16238   534.921883   552.548620\n",
      "20   29407  1206.710200  1260.674793\n",
      "21   24011   339.209607   358.428527\n",
      "22    8542   399.156407   405.994427\n",
      "23   14448   722.820683   738.584460\n",
      "24   19611   243.508187   253.090063\n",
      "25   30068  1196.247467  1256.934607\n",
      "26   26802   348.577240   365.997857\n",
      "27   26129  1726.713767  1796.245333\n",
      "28    7080   552.897203   556.246930\n",
      "29   23193   539.708713   568.449990\n",
      "30   19853   226.338937   234.353073\n",
      "31   26592  2193.038883  2343.384640\n",
      "32   22554   175.165063   185.203913\n",
      "33   24213   609.509147   638.488293\n",
      "34   23608   224.709170   244.322410\n",
      "35    7874   308.408663   311.652893\n",
      "36   19312   150.814623   155.279633\n",
      "37   25260   847.361723   878.212767\n",
      "38   28220   700.434360   736.043987\n",
      "39   10550   433.700330   437.877860\n",
      "40   27583   321.972263   351.392863\n",
      "41    6341   646.856297   667.236443\n",
      "42   26128  1597.928543  1658.333773\n",
      "43   25062   765.117403   831.773860\n",
      "44   23817  1209.741220  1274.481057\n",
      "45   19840   740.651237   771.851143\n",
      "46   11094   412.326110   465.768987\n",
      "47   10683   194.286253   195.017670\n",
      "48   29850  1712.384567  1828.178990\n",
      "49   26117   420.251993   424.115420\n",
      "50   30071  1585.309137  1660.782243\n",
      "51   11530   429.914747   435.676700\n",
      "52   26123  1168.237283  1270.683577\n",
      "53   20497   684.633293   710.416540\n",
      "54   28641   321.932157   334.127307\n",
      "55   22370  1352.184243  1429.280357\n",
      "56   25269   380.179313   395.690947\n",
      "57   14891   366.342643   372.428340\n",
      "58   16237   911.074083   933.257180\n",
      "59   10366   174.477983   176.525177\n",
      "60   26591   286.483217   297.139287\n",
      "61   22372   218.008700   243.843153\n",
      "62   19151  1025.115153  1080.472120\n",
      "63    6719   529.113270   532.585353\n",
      "64   17470  1529.466483  1768.985987\n",
      "65   23603   122.148117   130.133877\n",
      "66   29629  1910.278480  1927.349780\n",
      "67   16239   514.435203   531.578193\n",
      "68   17744  1482.291260  1494.296790\n",
      "69    6998   857.171653   862.486700\n",
      "70   18991   194.286253   195.017670\n",
      "71   21215  1025.851453  1072.869493\n",
      "72   31415   617.142697   635.975700\n",
      "73   26132  1583.937103  1623.908280\n",
      "74   23191   560.970000   579.025920\n",
      "75   21208   265.395993   276.612070\n",
      "76   30752  1414.562033  1492.498167\n",
      "77   27883   573.994123   577.444627\n",
      "78   24020   396.522993   405.719740\n",
      "79   23195   637.333293   650.016707\n",
      "80   16244   212.515187   231.398340\n",
      "81   24218   741.734217   785.851513\n",
      "82   23421  1347.564087  1430.706510\n",
      "83   17274  1513.171733  1542.915927\n",
      "84   25064   175.711040   189.091273\n",
      "85    8219  1514.489730  1549.363967\n",
      "86   25264  1600.357383  1725.663640\n",
      "87   23604  1174.553857  1203.412720\n",
      "88    6639   651.801820   661.801083\n",
      "89   26105  1158.023747  1173.112417\n",
      "90   23116  1189.945640  1275.657580\n",
      "91   28040  1188.092047  1216.652957\n",
      "92   27884   606.553073   643.826407\n",
      "93   26363  1170.231703  1206.204967\n",
      "94   26803  1603.488123  1659.753830\n",
      "95   20283  1265.036640  1274.246590\n",
      "96   30517  1587.801713  1644.386207\n",
      "97    6753   196.304347   217.810687\n",
      "98   27736   502.406830   524.675090\n",
      "99   30062   232.461753   250.133230\n",
      "100  27241  2263.048123  2372.627577\n",
      "101  11532   419.953053   432.135697\n",
      "102  13770   368.758040   373.105317\n",
      "103  25261   821.983907   868.946443\n",
      "104  29204   282.017763   291.947927\n",
      "105  30992  1403.465107  1448.387273\n",
      "106  16230  1301.184610  1360.930553\n",
      "107  30759   866.318673   912.958650\n",
      "108  28644  1367.793420  1439.364963\n",
      "109  27579   421.276537   443.896673\n",
      "110  29205   391.024143   411.841790\n",
      "111  20088   651.710170   671.190253\n",
      "112  26122   457.320300   480.482627\n",
      "113  27416   330.318287   339.221147\n",
      "114   7266   845.891370   882.558277\n",
      "115   4002  1083.027067  1121.042400\n",
      "116   6782   422.886293   434.502087\n",
      "117  26776  1404.160193  1451.788193\n",
      "118  19852   246.578753   249.116123\n",
      "119  12293   247.910877   254.812170\n",
      "120  28800   248.040183   259.744850\n",
      "121  30518   589.357687   606.407203\n",
      "122  22861  1336.540230  1353.081687\n",
      "123  27411   748.740457   774.815333\n",
      "124  26595   143.871580   149.458323\n",
      "125  30997   553.424537   569.881627\n",
      "126   8227  1032.204347  1079.074847\n",
      "127  24435  1225.200410  1237.551207\n",
      "128  23811   816.459567   833.126433\n",
      "129  27738   320.110027   331.469703\n",
      "130  10827   401.802197   414.150793\n",
      "131  21206   595.764427   622.156297\n",
      "132  17757   495.803677   517.100377\n",
      "133  19303   655.959327   671.408053\n",
      "134  21460  1100.691303  1170.486030\n",
      "135  25934   745.532663   790.423120\n",
      "136  15327   267.835907   270.285687\n",
      "137  20735   576.537267   607.634447\n",
      "138  10548  1080.455283  1144.722003\n",
      "139  20103  1497.372190  1549.390177\n",
      "140  26364   864.265403   942.653677\n",
      "141  26771   635.265320   650.080057\n",
      "142  12288   247.910877   254.812170\n",
      "143   7267   915.318770   953.220563\n",
      "144  16692   848.157693   865.631727\n",
      "145   7859   800.173287   806.265457\n",
      "146  27739   683.997320   704.543250\n",
      "147  26100  1755.826690  1832.300603\n",
      "148  23221   630.454253   664.890940\n",
      "149  25442   255.136410   264.202450\n",
      "150  22146   716.940970   764.717193\n",
      "151  20746   938.319963   983.284997\n",
      "152  29627  1350.816207  1354.123733\n",
      "153  22562   856.183060   870.977700\n",
      "154  11535   263.017270   268.954300\n",
      "155  27881   601.101677   625.452073\n",
      "156  26774   529.347177   546.985363\n",
      "157  26962  1131.365180  1227.796497\n",
      "158  23818  1509.748303  1558.211233\n",
      "159   4045   480.344463   488.903907\n",
      "160  25931  1622.070667  1661.996567\n",
      "161  20104  1331.266390  1392.687743\n",
      "162  24212   627.775420   654.236817\n",
      "163   3900   359.806850   366.520313\n",
      "164  11946   624.597167   638.446937\n",
      "165  20498   418.550237   427.110280\n",
      "166  17743  1480.233670  1525.843877\n",
      "167  28801  1415.574480  1463.117740\n",
      "168  19608   138.115763   145.214890\n",
      "169  27108   579.625607   621.677063\n",
      "170  30294   739.176740   767.361780\n",
      "171  17276  1346.412737  1387.636120\n",
      "172  16241  1318.422687  1353.551803\n",
      "173  20287   935.735250   992.552123\n",
      "174  31194   503.049173   519.065497\n",
      "175  30287   541.205840   553.122263\n",
      "176   3991   662.934120   674.673550\n",
      "177  23816   443.997873   467.119733\n",
      "178  26099   788.027090   841.073143\n",
      "179  30295  1911.411900  2027.530620\n",
      "180  20511   575.266830   593.254910\n",
      "181  13245  1035.347843  1068.508050\n",
      "182  29841  1437.091347  1572.297960\n",
      "183  23611  1045.340883  1103.137393\n",
      "184  11941   614.828660   660.037960\n",
      "185  21207   724.701643   756.350067\n",
      "186  17474   842.100010   854.483683\n",
      "187  26805   513.854783   532.954780\n",
      "188  26104  1615.381840  1800.527047\n",
      "189   7504  1164.180300  1197.873233\n",
      "190  28222   224.709170   244.322410\n",
      "191  26362   228.156393   241.623453\n",
      "192  28980   427.961353   452.781583\n",
      "193  26587  1338.809993  1386.811547\n",
      "194  25933  1394.806620  1453.173073\n",
      "195  26134   839.540260   883.428247\n",
      "196   6648   460.924320   481.233473\n",
      "197  25055   332.813847   341.811040\n",
      "198  18665  1450.117257  1509.915490\n",
      "199  23618   195.332693   223.795517\n",
      "200  24629   572.170067   589.467413\n",
      "201  23201   568.440863   593.764877\n",
      "202  29849   314.821477   331.502680\n",
      "203  26961  1860.174567  2050.236813\n",
      "204  28482  1292.056987  1363.878987\n",
      "205  28979  1172.167760  1216.319040\n",
      "206  31191  1159.041740  1214.899777\n",
      "207   8960   829.066523   844.236797\n",
      "208  29408   371.343780   382.690567\n",
      "209  23425   698.735417   742.737183\n",
      "210  23418   398.813980   418.001703\n",
      "211  14057  1779.777567  1855.593997\n",
      "212  20274   501.733777   537.406800\n",
      "213  30288  1883.236613  1968.206813\n",
      "214  27580  1561.057513  1647.420437\n",
      "215   9286   182.905247   187.131737\n",
      "216  27414   303.140707   310.505017\n",
      "217   8398   793.270620   854.001947\n",
      "218  21211  1241.223933  1320.745573\n",
      "219  22553  2380.189067  2427.438407\n",
      "220  28808   688.465863   737.345777\n",
      "221  23423  1444.533287  1593.044013\n"
     ]
    }
   ],
   "source": [
    "Model_Final = RandomForestRegressor(n_estimators = 1500,criterion='mae',random_state = 1)\n",
    "Model_Final.fit(X_train,Ya)\n",
    "Y_pred_test = Model_Final.predict(X_test)\n",
    "\n",
    "RESULTS = []\n",
    "for i in range(len(data2)):\n",
    "    temp_result = []\n",
    "    temp_result.append(data2['id'][i])\n",
    "    temp_result.append(Y_pred_test[i][0])\n",
    "    temp_result.append(Y_pred_test[i][1])\n",
    "    RESULTS.append(temp_result)\n",
    "\n",
    "RESULTS = pd.DataFrame(RESULTS)\n",
    "print(RESULTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS.to_csv(\"/Users/Simon/Documents/GitHub/adana123/RESULTS.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
