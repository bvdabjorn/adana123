{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Multi Target Random Forest Regression (MTRT)\n",
    "\n",
    "In this section we develop a multi target random forest regression for the prediction of a minimum and maximum price of laptop models.\n",
    "\n",
    "\n",
    "## 1. Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "## Edit Print options\n",
    "desired_width = 500\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dealing with missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Importing the preprocessed data\n",
    "missing_values = [\"n/a\", \"na\", \"--\",\"NAN\",\" \",\"nan\",\"NaN\",\"\"]\n",
    "data = pd.read_csv('datafile2.csv',na_values = missing_values)\n",
    "data2 = pd.read_csv('datafile2_test.csv',na_values = missing_values)\n",
    "\n",
    "## Removing missing values\n",
    "# data.dropna()\n",
    "\n",
    "## Just a temporary dataset to test the capabilities of the model\n",
    "temp_data = data[['brand','base_name','os_details','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                  'touchscreen','discrete_gpu','gpu','ram','ssd','detachable_keyboard','weight',\n",
    "                  'cpu_benchmark','gpu_benchmark','cpu_GHZ', 'min_price','max_price']]\n",
    "\n",
    "test_data = data2[['brand','base_name','os_details','gpu_brand','cpu_brand','cpu_type_name','gpu_type','screen_surface','screen_size','pixels_x',\n",
    "                   'touchscreen','discrete_gpu','gpu','ram','ssd', 'detachable_keyboard','weight',\n",
    "                   'cpu_benchmark','gpu_benchmark','cpu_GHZ']]\n",
    "\n",
    "concat_df = pd.concat([temp_data , test_data])\n",
    "concat_df.to_csv(\"/Users/Simon/Documents/GitHub/adana123/concat_df1.csv\",header=True,index=True)\n",
    "\n",
    "##### TRAINING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "temp_data['detachable_keyboard'] = temp_data['detachable_keyboard'].fillna(0)\n",
    "\n",
    "temp_data['gpu_brand'] = temp_data['gpu_brand'].fillna(\"Unknown\", inplace = True) \n",
    "temp_data['cpu_type_name'] = temp_data.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "temp_data['gpu_type'] = temp_data['gpu_type'].fillna(\"No GPU\", inplace = True) \n",
    "temp_data['screen_surface'] = temp_data['screen_surface'].fillna(\"Unknown\", inplace = True) \n",
    "temp_data['os_details'] = temp_data['os_details'].fillna(\"Unknown\", inplace = False) \n",
    "\n",
    "# ## Filling in missing values: NUMERICAL VARIABLES\n",
    "temp_data['weight'] = temp_data['weight'].fillna(temp_data['weight'].mean())\n",
    "temp_data['cpu_benchmark'] = temp_data['cpu_benchmark'].fillna(temp_data['cpu_benchmark'].mean()) \n",
    "temp_data['gpu_benchmark'] = temp_data['gpu_benchmark'].fillna(temp_data['gpu_benchmark'].mean())\n",
    "temp_data['cpu_GHZ'] = temp_data['cpu_GHZ'].fillna(temp_data['cpu_GHZ'].mean())\n",
    "temp_data['pixels_x'] = temp_data['pixels_x'].fillna(temp_data['pixels_x'].mode()) #Modus! Most frequent number! (median)\n",
    "\n",
    "## Showing the data\n",
    "# data.head()\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "##### TRAINING & TESTING DATA #####\n",
    "## Filling in missing values: CATEGORICAL & BINARY VARIABLES\n",
    "detach_key = int(temp_data.loc[:,'detachable_keyboard'].mode())\n",
    "concat_df.loc[:,'detachable_keyboard'] = concat_df.loc[:,'detachable_keyboard'].fillna(detach_key)\n",
    "# print(concat_df['detachable_keyboard'])\n",
    "concat_df['gpu_brand'] = concat_df['gpu_brand'].fillna(\"Unknown\", inplace = False) \n",
    "concat_df['cpu_type_name'] = concat_df.apply(lambda row: row['cpu_brand'] if pd.isnull(row['cpu_type_name']) \n",
    "                                             else row['cpu_type_name'], axis=1)\n",
    "\n",
    "concat_df['gpu_type'] = concat_df['gpu_type'].fillna(\"No GPU\", inplace = False)\n",
    "concat_df['gpu'] = concat_df['gpu'].fillna(\"No GPU\", inplace = False) \n",
    "concat_df['screen_surface'] = concat_df['screen_surface'].fillna(\"Unknown\", inplace = False) \n",
    "concat_df['os_details'] = concat_df['os_details'].fillna(\"Unknown\", inplace = False) \n",
    "\n",
    "## Filling in missing values: NUMERICAL VARIABLES\n",
    "concat_df['weight'] = concat_df['weight'].fillna(temp_data['weight'].mean())\n",
    "concat_df['cpu_benchmark'] = concat_df['cpu_benchmark'].fillna(temp_data['cpu_benchmark'].mean()) \n",
    "concat_df['gpu_benchmark'] = concat_df['gpu_benchmark'].fillna(temp_data['gpu_benchmark'].mean())\n",
    "concat_df['cpu_GHZ'] = concat_df['cpu_GHZ'].fillna(temp_data['cpu_GHZ'].mean())\n",
    "\n",
    "pixel_mode = int(temp_data.loc[:,'pixels_x'].mode())\n",
    "concat_df.loc[:,'pixels_x'] = concat_df.loc[:,'pixels_x'].fillna(pixel_mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "concat_df.to_csv(\"/Users/Simon/Documents/GitHub/adana123/concat_df2.csv\",header=True,index=True)\n",
    "\n",
    "#### Mean only from training set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance (Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting Data & Fitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mae',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Training Data ####\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat = temp_data[['brand','cpu_brand','gpu_brand','cpu_type_name','screen_surface','gpu']]#,'gpu_type','os_details','base_name'\n",
    "X_bin = temp_data[['touchscreen','discrete_gpu','detachable_keyboard']]\n",
    "X_num = temp_data[['screen_size','ram','ssd','weight','cpu_GHZ','pixels_x']]#,'cpu_benchmark','gpu_benchmark'\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies = pd.get_dummies(X_cat, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X = pd.concat([X_cat_dummies,X_bin,X_num], axis=1)\n",
    "# X = pd.concat([X_cat_dummies,X_num], axis=1)\n",
    "# X = X_cat_dummies\n",
    "\n",
    "## Defining output data\n",
    "Ya = temp_data[['min_price','max_price']]\n",
    "# Yb = temp_data[['min_price','diff_price']]\n",
    "\n",
    "########################################################################################\n",
    "## Seperating categorical - binary - numerical variables\n",
    "X_cat_test = concat_df[['brand','cpu_brand','gpu','gpu_brand','cpu_type_name','gpu_type','screen_surface']]#'os_details','base_name'\n",
    "X_bin_test = concat_df[['touchscreen','discrete_gpu','detachable_keyboard']]\n",
    "X_num_test = concat_df[['screen_size','ram','ssd','weight','cpu_GHZ','pixels_x','cpu_benchmark','gpu_benchmark']]\n",
    "\n",
    "## Creating dummy variables:\n",
    "X_cat_dummies_test = pd.get_dummies(X_cat_test, drop_first=True)\n",
    "\n",
    "## Merging input data\n",
    "X_full = pd.concat([X_cat_dummies_test,X_bin_test,X_num_test], axis=1)\n",
    "X_train = X_full.head(len(data))\n",
    "X_test = X_full.tail(len(data2))\n",
    "\n",
    "########################################################################################\n",
    "## Splitting the dataset into train and test sets\n",
    "# Predict Minimum and Maximum prices\n",
    "X_train_a, X_test_a, Y_train_a, Y_test_a = train_test_split(X, Ya, test_size=0.33, random_state=42)\n",
    "# Predict Minimum price and deviation from this price\n",
    "# X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(X, Yb, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_a.head()\n",
    "\n",
    "## 2 models\n",
    "Model1 = RandomForestRegressor(n_estimators = 100,criterion='mae',random_state = 1)\n",
    "Model1.fit(X_train_a,Y_train_a)\n",
    "\n",
    "# Model2 = RandomForestRegressor(n_estimators = 200,criterion='mae',random_state = 0)\n",
    "# Model2.fit(X_train_b,Y_train_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Measuring Mean Summed Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: MSAE for predicting minimum and maximum  price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.68249763313605\n",
      "321.5853696428571\n"
     ]
    }
   ],
   "source": [
    "## Predicting the target values\n",
    "Y_pred = Model1.predict(X_test_a)\n",
    "\n",
    "## Calculating the score\n",
    "MAE = mean_absolute_error(Y_test_a, Y_pred, multioutput='raw_values')\n",
    "print(MAE[0]+MAE[1])\n",
    "\n",
    "## Turn DF to array\n",
    "Y_test_array = Y_test_a.to_numpy()\n",
    "\n",
    "Sum_error = 0\n",
    "Y_pred_min_array = []\n",
    "for i in range(len(Y_pred)):\n",
    "#     print(Y_pred[i],Y_test_array[i])\n",
    "    Y_pred_min = Y_pred[i][0]\n",
    "    Y_pred_max = Y_pred[i][1]\n",
    "    Y_test_min = Y_test_array[i][0]\n",
    "    Y_test_max = Y_test_array[i][1]\n",
    "    \n",
    "    Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "    Error_min = abs(Y_pred_min - Y_test_min)\n",
    "    Error_max = abs(Y_pred_max - Y_test_max)\n",
    "    Total_error = Error_min + Error_max\n",
    "    \n",
    "    Sum_error = Sum_error + Total_error\n",
    "    counter = i\n",
    "\n",
    "Avg_error = Sum_error / counter\n",
    "MSAE = Avg_error\n",
    "print(MSAE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: MSAE for predicting minimum price and price difference\n",
    "\n",
    "**Result:** No significant improvement was obtained. This is as expected because the regression tree considers the two outputs, min and max price, at the same time. They are not considered independent and the splits are based on improving both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = Model2.predict(X_test_b)\n",
    "\n",
    "# ## Turn DF to array\n",
    "# Y_test_array = Y_test_b.to_numpy()\n",
    "\n",
    "# Sum_error = 0\n",
    "# Y_pred_min_array = []\n",
    "# for i in range(len(Y_pred)):\n",
    "# #     print(Y_pred[i],Y_test_array[i])\n",
    "#     Y_pred_min = Y_pred[i][0]\n",
    "#     Y_pred_max = Y_pred_min + Y_pred[i][1]\n",
    "#     Y_test_min = Y_test_array[i][0]\n",
    "#     Y_test_max = Y_test_min + Y_test_array[i][1]\n",
    "    \n",
    "#     Y_pred_min_array.append(Y_pred_min)\n",
    "    \n",
    "#     Error_min = abs(Y_pred_min - Y_test_min)\n",
    "#     Error_max = abs(Y_pred_max - Y_test_max)\n",
    "#     Total_error = Error_min + Error_max\n",
    "    \n",
    "#     Sum_error = Sum_error + Total_error\n",
    "#     counter = i\n",
    "\n",
    "# Avg_error = Sum_error / counter\n",
    "# MSAE = Avg_error\n",
    "# print('The MSAE = ', round(MSAE,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the decision tree\n",
    "# FEATURE_NAMES = X_train.columns[:]\n",
    "\n",
    "\n",
    "# dot_data = export_graphviz(Model1,\n",
    "#                                out_file=None,\n",
    "#                                feature_names=FEATURE_NAMES,\n",
    "#                                filled = True)\n",
    "# graph = Source(dot_data)\n",
    "\n",
    "# # dot_data = io.StringIO()\n",
    "# # export_graphviz(Model1, out_file=dot_data, rounded=True, filled=True)\n",
    "# # filename = \"tree.png\"\n",
    "# # pydotplus.graph_from_dot_data(dot_data.getvalue()).write_png(filename)\n",
    "# # plt.figure(figsize=(300,100))\n",
    "# # img = mpimg.imread(filename)\n",
    "# # imgplot = plt.imshow(img)\n",
    "# # plt.show()\n",
    "\n",
    "# plt.figure(figsize=(120,50))\n",
    "# plot_tree(Model1, feature_names=FEATURE_NAMES,fontsize=11, rounded=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results \n",
    "  \n",
    "# arange for creating a range of values \n",
    "# from min value of x to max  \n",
    "# value of x with a difference of 0.01  \n",
    "# between two consecutive values \n",
    "# X_grid = np.arange(X_test, max(x), 0.01)  \n",
    "# X_ram\n",
    "  \n",
    "# reshape for reshaping the data into a len(X_grid)*1 array,  \n",
    "# i.e. to make a column out of the X_grid value                   \n",
    "# X_grid = X_grid.reshape((len(X_grid), 1)) \n",
    "  \n",
    "# Scatter plot for original data \n",
    "# plt.scatter(x, y, color = 'blue')   \n",
    "  \n",
    "# plot predicted data \n",
    "# plt.plot(Y_pred_min_array,  \n",
    "#          color = 'green')  \n",
    "# plt.title('Random Forest Regression') \n",
    "# plt.xlabel('Position level') \n",
    "# plt.ylabel('Max_price') \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0            1            2\n",
      "0    28807  1145.900515  1214.424845\n",
      "1    22559   384.238435   401.199165\n",
      "2    28647   787.307420   818.843230\n",
      "3    22141   525.181825   544.099305\n",
      "4    26116  2070.852230  2258.131030\n",
      "5    27111  1352.791120  1399.565130\n",
      "6    23420   609.725945   635.258840\n",
      "7    21464   186.433140   192.890625\n",
      "8    29405   729.090325   766.278475\n",
      "9    27107   395.410330   405.608615\n",
      "10   26141   939.515660   973.619190\n",
      "11   25928  1549.611415  1658.296720\n",
      "12   24845   714.503900   770.309440\n",
      "13   28804   359.498665   377.767285\n",
      "14   26772   607.776625   615.346155\n",
      "15   27413   914.778110   941.755370\n",
      "16    7261   853.705100   896.528920\n",
      "17   31424   783.663000   804.042105\n",
      "18    3940   421.289455   430.860235\n",
      "19   16238   530.275220   548.869615\n",
      "20   29407  1204.709470  1253.337185\n",
      "21   24011   338.141380   357.947060\n",
      "22    8542   390.783045   399.088780\n",
      "23   14448   704.558620   719.857710\n",
      "24   19611   233.742515   243.896485\n",
      "25   30068  1203.861410  1264.879710\n",
      "26   26802   322.801420   338.649480\n",
      "27   26129  1727.391610  1794.305810\n",
      "28    7080   549.046440   553.137590\n",
      "29   23193   541.021880   571.694905\n",
      "30   19853   221.940960   230.221525\n",
      "31   26592  2108.099980  2264.023435\n",
      "32   22554   176.321430   186.057295\n",
      "33   24213   611.213250   639.775990\n",
      "34   23608   223.373700   242.721695\n",
      "35    7874   305.640795   308.738545\n",
      "36   19312   150.384565   154.731850\n",
      "37   25260   845.502240   874.362140\n",
      "38   28220   700.697210   737.548615\n",
      "39   10550   427.441030   431.491135\n",
      "40   27583   328.157420   356.021340\n",
      "41    6341   624.266795   651.064100\n",
      "42   26128  1571.844855  1623.933965\n",
      "43   25062   765.309850   829.399800\n",
      "44   23817  1207.639875  1266.844140\n",
      "45   19840   748.229605   777.878940\n",
      "46   11094   397.351205   447.533165\n",
      "47   10683   192.585030   193.415700\n",
      "48   29850  1724.160750  1835.463670\n",
      "49   26117   419.919590   423.299655\n",
      "50   30071  1584.660400  1660.011870\n",
      "51   11530   429.392240   436.257905\n",
      "52   26123  1173.981545  1277.453225\n",
      "53   20497   687.110370   714.029470\n",
      "54   28641   313.309265   325.913175\n",
      "55   22370  1366.971575  1445.019040\n",
      "56   25269   381.387420   398.054240\n",
      "57   14891   351.879270   356.772310\n",
      "58   16237   901.793725   924.615260\n",
      "59   10366   174.922105   176.875175\n",
      "60   26591   289.202440   299.728380\n",
      "61   22372   222.396095   251.581440\n",
      "62   19151  1005.537450  1064.351635\n",
      "63    6719   528.738820   532.577465\n",
      "64   17470  1490.999605  1711.668925\n",
      "65   23603   123.505730   131.453730\n",
      "66   29629  1902.852405  1919.814630\n",
      "67   16239   511.485835   525.335270\n",
      "68   17744  1516.255265  1529.970360\n",
      "69    6998   855.611695   861.670215\n",
      "70   18991   192.585030   193.415700\n",
      "71   21215  1023.197420  1072.828175\n",
      "72   31415   617.790885   635.916695\n",
      "73   26132  1594.449860  1642.755785\n",
      "74   23191   559.638470   577.687020\n",
      "75   21208   236.326120   244.902360\n",
      "76   30752  1415.554180  1493.693600\n",
      "77   27883   572.849820   575.531085\n",
      "78   24020   377.059725   388.287565\n",
      "79   23195   636.501325   650.369580\n",
      "80   16244   211.293040   230.504270\n",
      "81   24218   740.687115   782.311580\n",
      "82   23421  1339.415825  1423.786460\n",
      "83   17274  1564.240395  1591.901860\n",
      "84   25064   172.849730   185.917425\n",
      "85    8219  1510.978810  1555.946050\n",
      "86   25264  1575.829830  1708.623710\n",
      "87   23604  1182.537570  1212.537070\n",
      "88    6639   645.098390   653.761250\n",
      "89   26105  1193.695035  1208.786260\n",
      "90   23116  1208.639365  1293.240920\n",
      "91   28040  1207.982200  1236.819510\n",
      "92   27884   607.229625   643.376500\n",
      "93   26363  1180.400345  1219.213635\n",
      "94   26803  1607.123915  1657.980205\n",
      "95   20283  1262.706460  1273.664150\n",
      "96   30517  1569.921005  1614.529835\n",
      "97    6753   195.451150   216.997990\n",
      "98   27736   499.269680   520.270835\n",
      "99   30062   236.000575   253.895450\n",
      "100  27241  2186.701150  2285.533015\n",
      "101  11532   424.515215   435.757015\n",
      "102  13770   360.120995   363.259860\n",
      "103  25261   823.410720   866.844160\n",
      "104  29204   274.564715   285.042305\n",
      "105  30992  1402.545940  1449.700445\n",
      "106  16230  1316.262930  1365.488500\n",
      "107  30759   863.893780   911.065615\n",
      "108  28644  1369.896635  1441.282845\n",
      "109  27579   415.684610   438.176175\n",
      "110  29205   388.426235   407.095840\n",
      "111  20088   665.404680   684.724960\n",
      "112  26122   458.138345   482.592730\n",
      "113  27416   326.883870   336.542220\n",
      "114   7266   820.957825   853.966940\n",
      "115   4002  1160.335390  1202.606655\n",
      "116   6782   406.484260   416.314010\n",
      "117  26776  1431.697825  1474.743990\n",
      "118  19852   246.291855   248.146575\n",
      "119  12293   242.213360   249.219165\n",
      "120  28800   257.682975   267.328880\n",
      "121  30518   589.114750   605.179265\n",
      "122  22861  1342.675355  1364.961740\n",
      "123  27411   717.849040   746.224050\n",
      "124  26595   143.041130   148.705835\n",
      "125  30997   555.074125   571.165610\n",
      "126   8227  1015.069740  1059.736660\n",
      "127  24435  1248.555010  1259.548080\n",
      "128  23811   810.396220   828.001030\n",
      "129  27738   338.155345   353.540530\n",
      "130  10827   403.960455   416.654970\n",
      "131  21206   597.527625   622.142525\n",
      "132  17757   538.896290   562.004850\n",
      "133  19303   659.908085   676.019435\n",
      "134  21460  1093.977650  1167.112310\n",
      "135  25934   745.690335   789.323515\n",
      "136  15327   266.912885   269.476270\n",
      "137  20735   578.628445   611.156895\n",
      "138  10548  1042.226245  1105.028000\n",
      "139  20103  1495.152865  1539.570540\n",
      "140  26364   863.623320   938.732095\n",
      "141  26771   639.321105   654.078150\n",
      "142  12288   242.213360   249.219165\n",
      "143   7267   905.572095   940.726030\n",
      "144  16692   846.121695   861.558800\n",
      "145   7859   811.206450   815.882890\n",
      "146  27739   679.051555   699.130230\n",
      "147  26100  1777.497640  1858.624540\n",
      "148  23221   632.291635   667.035260\n",
      "149  25442   252.356200   261.381035\n",
      "150  22146   718.018265   770.036055\n",
      "151  20746   907.947415   947.121580\n",
      "152  29627  1350.101585  1354.581625\n",
      "153  22562   866.127800   881.629410\n",
      "154  11535   257.855475   263.258825\n",
      "155  27881   607.972680   629.445265\n",
      "156  26774   526.695400   545.146820\n",
      "157  26962  1133.370700  1230.712580\n",
      "158  23818  1481.860420  1535.540915\n",
      "159   4045   493.862415   501.376630\n",
      "160  25931  1621.699550  1662.796370\n",
      "161  20104  1337.429075  1397.506475\n",
      "162  24212   639.985680   665.980005\n",
      "163   3900   362.523875   369.531440\n",
      "164  11946   618.102630   633.623250\n",
      "165  20498   416.967160   424.923435\n",
      "166  17743  1470.574125  1520.984820\n",
      "167  28801  1433.255380  1475.714800\n",
      "168  19608   140.110870   147.001085\n",
      "169  27108   576.482800   618.785995\n",
      "170  30294   717.074060   743.171710\n",
      "171  17276  1365.311605  1412.724740\n",
      "172  16241  1327.836970  1365.317550\n",
      "173  20287   879.824755   935.280880\n",
      "174  31194   415.306460   430.480160\n",
      "175  30287   543.430890   553.783620\n",
      "176   3991   668.153685   678.638260\n",
      "177  23816   426.463550   446.457125\n",
      "178  26099   797.050455   848.655470\n",
      "179  30295  1907.263170  2019.362190\n",
      "180  20511   574.198935   592.930800\n",
      "181  13245  1036.806680  1070.634640\n",
      "182  29841  1477.191175  1614.096695\n",
      "183  23611   996.337845  1052.735810\n",
      "184  11941   606.938950   654.866480\n",
      "185  21207   726.026175   757.578060\n",
      "186  17474   835.937180   847.617545\n",
      "187  26805   512.929850   532.392720\n",
      "188  26104  1687.493020  1869.804610\n",
      "189   7504  1173.691800  1200.137495\n",
      "190  28222   223.373700   242.721695\n",
      "191  26362   226.354760   239.849840\n",
      "192  28980   417.312765   441.090220\n",
      "193  26587  1346.873545  1392.600100\n",
      "194  25933  1483.181305  1535.643425\n",
      "195  26134   824.803580   869.884460\n",
      "196   6648   429.175525   451.024685\n",
      "197  25055   329.540480   339.302240\n",
      "198  18665  1457.960700  1520.832075\n",
      "199  23618   195.311770   224.439355\n",
      "200  24629   572.495080   589.425865\n",
      "201  23201   555.101895   581.676245\n",
      "202  29849   312.497050   328.928875\n",
      "203  26961  1852.290685  2042.519730\n",
      "204  28482  1330.648080  1403.736200\n",
      "205  28979  1192.247610  1236.572125\n",
      "206  31191  1152.584710  1208.802610\n",
      "207   8960   850.842345   866.052825\n",
      "208  29408   367.704660   378.811360\n",
      "209  23425   702.303190   743.944780\n",
      "210  23418   398.289695   418.259520\n",
      "211  14057  1757.955525  1813.338545\n",
      "212  20274   502.307240   539.679870\n",
      "213  30288  1893.066370  1980.828180\n",
      "214  27580  1567.310670  1658.131280\n",
      "215   9286   183.387455   187.327115\n",
      "216  27414   300.719450   308.434330\n",
      "217   8398   728.560490   784.430700\n",
      "218  21211  1258.454090  1338.268015\n",
      "219  22553  2395.368075  2435.505110\n",
      "220  28808   695.413930   741.856820\n",
      "221  23423  1471.203705  1613.983275\n"
     ]
    }
   ],
   "source": [
    "Model_Final = RandomForestRegressor(n_estimators = 1000,criterion='mae',random_state = 1)\n",
    "Model_Final.fit(X_train,Ya)\n",
    "Y_pred_test = Model_Final.predict(X_test)\n",
    "\n",
    "RESULTS = []\n",
    "for i in range(len(data2)):\n",
    "    temp_result = []\n",
    "    temp_result.append(data2['id'][i])\n",
    "    temp_result.append(Y_pred_test[i][0])\n",
    "    temp_result.append(Y_pred_test[i][1])\n",
    "    RESULTS.append(temp_result)\n",
    "\n",
    "RESULTS = pd.DataFrame(RESULTS)\n",
    "print(RESULTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS.to_csv(\"/Users/Simon/Documents/GitHub/adana123/RESULTS.csv\",header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
